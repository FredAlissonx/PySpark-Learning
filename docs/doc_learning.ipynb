{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Doc Learning\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"C:\\Education\\PySpark-Learning\\data\\data_per_100k_habitants.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Aggregation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate on the entire DataFrame without groups (shorthand for df.groupBy().agg())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_sample = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(age)|\n",
      "+--------+\n",
      "|       5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 1 - simple operations\n",
    "agg_df_1 = agg_sample.agg({\"age\": \"max\"})\n",
    "agg_df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|min(name)|max(age)|\n",
      "+---------+--------+\n",
      "|    Alice|       5|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 2 - aggregating multiple columns\n",
    "agg_df_2 = agg_sample.agg(\n",
    "    {\n",
    "        \"age\": \"max\",\n",
    "        \"name\": \"min\"\n",
    "    }\n",
    ")\n",
    "agg_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|MAX_AGE|NAME_COUNT|\n",
      "+-------+----------+\n",
      "|      5|         2|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exempla 3 - using sql functions for aggregations\n",
    "agg_df_3 = agg_sample.agg(\n",
    "    F.max(\"age\").alias(\"MAX_AGE\"),\n",
    "    F.count(\"name\").alias(\"NAME_COUNT\")\n",
    ").select(\"MAX_AGE\", \"NAME_COUNT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|age|count(1)|\n",
      "+---+--------+\n",
      "|  2|       1|\n",
      "|  5|       1|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 4 - using with groupBy\n",
    "agg_df_4 = agg_sample.groupBy(F.col(\"age\")).agg(F.count(\"*\"))\n",
    "agg_df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+---------+\n",
      "|min_age|max_age|avg_age|count_age|\n",
      "+-------+-------+-------+---------+\n",
      "|      2|      5|    3.5|        2|\n",
      "+-------+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 5 - Aggregating with Multiple Functions on the Same Column\n",
    "agg_df_5 = agg_sample.agg(\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"age\").alias(\"max_age\"),\n",
    "    F.avg(\"age\").alias(\"avg_age\"),\n",
    "    F.count(\"age\").alias(\"count_age\")\n",
    ")\n",
    "agg_df_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "| name|custom_age_mean|\n",
      "+-----+---------------+\n",
      "|Alice|            2.0|\n",
      "|  Bob|            5.0|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 6 - using custom aggregations\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# Define a UDF for custom aggregation\n",
    "@F.udf(T.DoubleType())\n",
    "def custom_agg(values):\n",
    "    return sum(values) / len(values)  # Custom example: mean calculation\n",
    "\n",
    "# Apply custom aggregation\n",
    "agg_df_6 = agg_sample.groupBy(\"name\").agg(\n",
    "    custom_agg(F.collect_list(\"age\")).alias(\"custom_age_mean\")\n",
    ")\n",
    "agg_df_6.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises \"agg\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+---+------+----------+\n",
      "| id|     name|department|age|salary|experience|\n",
      "+---+---------+----------+---+------+----------+\n",
      "|  1|    Alice|     Sales| 34| 70000|         5|\n",
      "|  2|      Bob|        HR| 45| 80000|        10|\n",
      "|  3|Catherine|        IT| 29| 90000|         3|\n",
      "|  4|    David|        IT| 39| 85000|         7|\n",
      "|  5|      Eve|     Sales| 41| 75000|         8|\n",
      "|  6|    Frank|        HR| 30| 60000|         2|\n",
      "|  7|    Grace|        IT| 35| 95000|         6|\n",
      "|  8|   Hannah|     Sales| 50| 65000|        12|\n",
      "|  9|      Ivy|        IT| 38| 87000|         9|\n",
      "| 10|     Jack|        HR| 28| 72000|         4|\n",
      "+---+---------+----------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "data = [(1, \"Alice\", \"Sales\", 34, 70000, 5),\n",
    "        (2, \"Bob\", \"HR\", 45, 80000, 10),\n",
    "        (3, \"Catherine\", \"IT\", 29, 90000, 3),\n",
    "        (4, \"David\", \"IT\", 39, 85000, 7),\n",
    "        (5, \"Eve\", \"Sales\", 41, 75000, 8),\n",
    "        (6, \"Frank\", \"HR\", 30, 60000, 2),\n",
    "        (7, \"Grace\", \"IT\", 35, 95000, 6),\n",
    "        (8, \"Hannah\", \"Sales\", 50, 65000, 12),\n",
    "        (9, \"Ivy\", \"IT\", 38, 87000, 9),\n",
    "        (10, \"Jack\", \"HR\", 28, 72000, 4)]\n",
    "\n",
    "columns = [\"id\", \"name\", \"department\", \"age\", \"salary\", \"experience\"]\n",
    "\n",
    "agg_sample = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the sample data\n",
    "agg_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------+\n",
      "|max_age|avg_salary|total_experience|\n",
      "+-------+----------+----------------+\n",
      "|     50|   77900.0|              66|\n",
      "+-------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question 1: Find the maximum age, average salary, and total experience for all employees.\n",
    "q1 = agg_sample.agg(\n",
    "    F.max(\"age\").alias(\"max_age\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.sum(\"experience\").alias(\"total_experience\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----------------+----------------+\n",
      "|department|max_age|       avg_salary|total_experience|\n",
      "+----------+-------+-----------------+----------------+\n",
      "|     Sales|     50|          70000.0|              25|\n",
      "|        HR|     45|70666.66666666667|              16|\n",
      "|        IT|     39|          89250.0|              25|\n",
      "+----------+-------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question 2: Group the employees by department and find the maximum age, average salary, and total experience for each department.\n",
    "q2 = agg_sample.groupBy(\"department\").agg(\n",
    "    F.max(\"age\").alias(\"max_age\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.sum(\"experience\").alias(\"total_experience\")\n",
    ").select(\n",
    "    \"department\",\n",
    "    \"max_age\",\n",
    "    \"avg_salary\",\n",
    "    \"total_experience\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------+\n",
      "|min_age|max_salary|employee_count|\n",
      "+-------+----------+--------------+\n",
      "|     28|     95000|            10|\n",
      "+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question 3: Find the minimum age, maximum salary, and count of employees.\n",
    "q3 = agg_sample.agg(\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"salary\").alias(\"max_salary\"),\n",
    "    F.count(\"*\").alias(\"employee_count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+--------------+\n",
      "|department|min_age|max_salary|employee_count|\n",
      "+----------+-------+----------+--------------+\n",
      "|     Sales|     34|     75000|             3|\n",
      "|        HR|     28|     80000|             3|\n",
      "|        IT|     29|     95000|             4|\n",
      "+----------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question 4 - Group the employees by department and find the minimum age,\n",
    "# maximum salary, and count of employees for each department.\n",
    "q4 = agg_sample.groupBy(\"department\").agg(\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"salary\").alias(\"max_salary\"),\n",
    "    F.count(\"*\").alias(\"employee_count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_DICT] Argument `colsMap` should be a dict, got set.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m q5 \u001b[38;5;241m=\u001b[39m agg_sample\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m })\n\u001b[0;32m      6\u001b[0m columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_salary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_age\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 8\u001b[0m q5_df \u001b[38;5;241m=\u001b[39m \u001b[43mq5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Education\\PySpark_Learning\\.conda\\lib\\site-packages\\pyspark\\sql\\dataframe.py:5113\u001b[0m, in \u001b[0;36mDataFrame.withColumns\u001b[1;34m(self, *colsMap)\u001b[0m\n\u001b[0;32m   5110\u001b[0m colsMap \u001b[38;5;241m=\u001b[39m colsMap[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   5112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(colsMap, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m-> 5113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   5114\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_DICT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5115\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsMap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(colsMap)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   5116\u001b[0m     )\n\u001b[0;32m   5118\u001b[0m col_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(colsMap\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m   5119\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(colsMap\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[1;31mPySparkTypeError\u001b[0m: [NOT_DICT] Argument `colsMap` should be a dict, got set."
     ]
    }
   ],
   "source": [
    "# question 5 - Find the average age and total salary of employees.\n",
    "q5 = agg_sample.agg({\n",
    "    \"age\": \"avg\",\n",
    "    \"salary\": \"sum\"\n",
    "})\n",
    "columns = [\"total_salary\", \"avg_age\"\n",
    "\n",
    "q5_df = q5.withColumns(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - withColumn function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função withColumn no PySpark é usada para adicionar uma nova coluna a um DataFrame ou para substituir uma coluna existente com base em uma expressão especificada\n",
    "\n",
    "Syntax:\n",
    "\n",
    "**DataFrame.withColumn(colName, col)**\n",
    "\n",
    "colName: O nome da nova coluna ou da coluna existente a ser substituída.\n",
    "col: Uma expressão que define os valores da coluna, que pode ser uma instância de Column, uma expressão SQL, ou uma função do módulo pyspark.sql.functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adicionar uma nova coluna**\n",
    "\n",
    "Vamos adicionar uma nova coluna chamada \"idade_5_anos\" que será a idade atual acrescida de 5 anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Alice\", 34), (\"Bob\", 45), (\"Catherine\", 29)]\n",
    "columns = [\"Nome\", \"Idade\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Adicionar uma nova coluna \"idade_5_anos\"\n",
    "df = df.withColumn(\"idade_5_anos\", F.col(\"Idade\") + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+\n",
      "|     Nome|Idade|idade_5_anos|\n",
      "+---------+-----+------------+\n",
      "|    Alice|   34|          39|\n",
      "|      Bob|   45|          50|\n",
      "|Catherine|   29|          34|\n",
      "+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Substituir uma coluna existente**\n",
    "\n",
    "Vamos substituir a coluna \"Idade\" com a idade acrescida de 10 anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+\n",
      "|     Nome|Idade|idade_5_anos|\n",
      "+---------+-----+------------+\n",
      "|    Alice|   44|          39|\n",
      "|      Bob|   55|          50|\n",
      "|Catherine|   39|          34|\n",
      "+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Idade\", F.col(\"Idade\") + 10)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converter tipos de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+\n",
      "|     Nome|Idade|idade_5_anos|\n",
      "+---------+-----+------------+\n",
      "|    Alice|   44|          39|\n",
      "|      Bob|   55|          50|\n",
      "|Catherine|   39|          34|\n",
      "+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converter uma coluna de string para inteiro\n",
    "df = df.withColumn(\"Idade\", F.col(\"Idade\").cast(\"int\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicar funções SQL integradas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+--------+\n",
      "|     Nome|Idade|idade_5_anos|AnoAtual|\n",
      "+---------+-----+------------+--------+\n",
      "|    Alice|   44|          39|    2024|\n",
      "|      Bob|   55|          50|    2024|\n",
      "|Catherine|   39|          34|    2024|\n",
      "+---------+-----+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adicionar uma nova coluna \"AnoAtual\" usando a função current_year\n",
    "df = df.withColumn(\"AnoAtual\", F.year(F.current_date()))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criar uma coluna calculada com base em outras colunas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar uma nova coluna \"SalarioAnual\" que é \"SalarioMensal\" vezes 12\n",
    "df = df.withColumn(\"SalarioAnual\", F.col(\"SalarioMensal\") * 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
